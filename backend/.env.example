# Backend Configuration Example
# Copy this file to .env and update with your values

# Server Configuration
HOST=localhost
PORT=8000

# TensorFlow Serving
TF_SERVING_ENDPOINT=http://localhost:8501/v1/models/potatoes_model:predict

# CORS Origins (comma-separated)
ALLOWED_ORIGINS=http://localhost:5500,http://localhost:3000,http://127.0.0.1:5500

# File Upload Settings
MAX_FILE_SIZE_MB=10
ALLOWED_IMAGE_EXTENSIONS=.jpg,.jpeg,.png,.webp

# Translation Settings
LIBRE_TRANSLATE_URL=https://libretranslate.com

# Ollama Settings (AI Chatbot)
OLLAMA_ENDPOINT=http://localhost:11434/api/generate
OLLAMA_MODEL=llama3.2

# Rate Limiting
RATE_LIMIT_PER_MINUTE=10
RATE_LIMIT_PER_HOUR=100

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

# Environment
ENVIRONMENT=development
DEBUG=True
